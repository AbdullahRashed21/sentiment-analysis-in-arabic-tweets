{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jSruXPbawAA5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn \n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>هه خلي فضولش ف جيبش 🌚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>موجود ماسافرت 😊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>: مسابقة #43 #متابعي_شامخ فقط# 🔘السحب على200💰ر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>اللهم امين 🌺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>يعني اذا ما احبج احب منو؟ 💘</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       pos                              هه خلي فضولش ف جيبش 🌚\n",
       "1       pos                                    موجود ماسافرت 😊\n",
       "2       pos  : مسابقة #43 #متابعي_شامخ فقط# 🔘السحب على200💰ر...\n",
       "3       pos                                       اللهم امين 🌺\n",
       "4       pos                        يعني اذا ما احبج احب منو؟ 💘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sentiment','text']\n",
    "positive = pd.read_csv('Arabic_tweets_positive.tsv',sep='\\t', error_bad_lines = False ,header=None, names=cols)\n",
    "positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>انمي Family Guy الموسم الحلقة السادسة مترجمة H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>صدااع من الغباء لي ساعه افكر وش اقول بس غبائها...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>قتيلا وجريحا… حصيلة تفرقة المتظاهرين في كربلاء...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>اللهم من أصلح شأنهم وجمع كلمتهم ووحد صفهم ياقا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>كوميديا.. الذهبية تذهب بالخطأ لصاحبة المركز ال...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       neg  انمي Family Guy الموسم الحلقة السادسة مترجمة H...\n",
       "1       neg  صدااع من الغباء لي ساعه افكر وش اقول بس غبائها...\n",
       "2       neg  قتيلا وجريحا… حصيلة تفرقة المتظاهرين في كربلاء...\n",
       "3       neg  اللهم من أصلح شأنهم وجمع كلمتهم ووحد صفهم ياقا...\n",
       "4       neg  كوميديا.. الذهبية تذهب بالخطأ لصاحبة المركز ال..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sentiment','text']\n",
    "negative = pd.read_csv('Arabic_tweets_negative.tsv',sep='\\t', error_bad_lines = False ,header=None, names=cols)\n",
    "negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>هه خلي فضولش ف جيبش 🌚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>موجود ماسافرت 😊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>: مسابقة #43 #متابعي_شامخ فقط# 🔘السحب على200💰ر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>اللهم امين 🌺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>يعني اذا ما احبج احب منو؟ 💘</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       pos                              هه خلي فضولش ف جيبش 🌚\n",
       "1       pos                                    موجود ماسافرت 😊\n",
       "2       pos  : مسابقة #43 #متابعي_شامخ فقط# 🔘السحب على200💰ر...\n",
       "3       pos                                       اللهم امين 🌺\n",
       "4       pos                        يعني اذا ما احبج احب منو؟ 💘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.concat([positive, negative], axis=0)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55531</td>\n",
       "      <td>neg</td>\n",
       "      <td>إشتقت لي المشاكس 💔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21768</td>\n",
       "      <td>neg</td>\n",
       "      <td>ماشى يا مدام نظيفه يا فيتكه انتى 🤣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64659</td>\n",
       "      <td>pos</td>\n",
       "      <td>تبقى تبقى 🌺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27550</td>\n",
       "      <td>pos</td>\n",
       "      <td>: إن الكرام وإن ضاقت معيشتهم دامت فضيلتهم والأ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54625</td>\n",
       "      <td>neg</td>\n",
       "      <td>هه أموت في خفة الدم 😭</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index sentiment                                               text\n",
       "0  55531       neg                                 إشتقت لي المشاكس 💔\n",
       "1  21768       neg                 ماشى يا مدام نظيفه يا فيتكه انتى 🤣\n",
       "2  64659       pos                                        تبقى تبقى 🌺\n",
       "3  27550       pos  : إن الكرام وإن ضاقت معيشتهم دامت فضيلتهم والأ...\n",
       "4  54625       neg                              هه أموت في خفة الدم 😭"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "final_data = shuffle(final_data).reset_index()\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>إشتقت لي المشاكس 💔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>ماشى يا مدام نظيفه يا فيتكه انتى 🤣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>تبقى تبقى 🌺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>: إن الكرام وإن ضاقت معيشتهم دامت فضيلتهم والأ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>هه أموت في خفة الدم 😭</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       neg                                 إشتقت لي المشاكس 💔\n",
       "1       neg                 ماشى يا مدام نظيفه يا فيتكه انتى 🤣\n",
       "2       pos                                        تبقى تبقى 🌺\n",
       "3       pos  : إن الكرام وإن ضاقت معيشتهم دامت فضيلتهم والأ...\n",
       "4       neg                              هه أموت في خفة الدم 😭"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = final_data.drop('index',axis=1)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9fjqEWp5wAA7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive tweets:  148328\n"
     ]
    }
   ],
   "source": [
    "print(\"positive tweets: \",len(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3zrjwcqwAA8",
    "outputId": "46916c70-4764-4910-f0a2-4a52f6387ef2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    False\n",
       "text         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8mCOcjqNwAA9"
   },
   "outputs": [],
   "source": [
    "for letter in '#.][!XR':\n",
    "    final_data['text'] = final_data['text'].astype(str).str.replace(letter,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5u750zCNwAA9"
   },
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eSANy9pUwAA-"
   },
   "outputs": [],
   "source": [
    "def remove_non_arabic(text):\n",
    "    return ' '.join(re.sub(u\"[^\\u0621-\\u063A\\u0640-\\u0652 ]\", \" \", str(text),  flags=re.UNICODE).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cgCnCDxUwAA_"
   },
   "outputs": [],
   "source": [
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bGnVwTL0wAA_"
   },
   "outputs": [],
   "source": [
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "D53C2zHuwABA"
   },
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hde3GRIWwABA"
   },
   "outputs": [],
   "source": [
    "def processPost(tweet): \n",
    "\n",
    "    #Replace @username with empty string\n",
    "    tweet = re.sub('@[^\\s]+', ' ', tweet)\n",
    "    \n",
    "    #Convert www.* or https?://* to \" \"\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',tweet)\n",
    "    \n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "\n",
    "    # remove punctuations\n",
    "    tweet= remove_punctuations(tweet)\n",
    "    \n",
    "    # normalize the tweet\n",
    "    tweet= normalize_arabic(tweet)\n",
    "    \n",
    "    # remove repeated letters\n",
    "    #tweet=remove_repeating_char(tweet)\n",
    "\n",
    "\n",
    "    # remove emoji\n",
    "    tweet=remove_emoji(tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OV5sI8hDwABB"
   },
   "outputs": [],
   "source": [
    "final_data[\"text\"] = final_data['text'].apply(lambda x: processPost(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rWVPNnibwABB"
   },
   "outputs": [],
   "source": [
    "final_data[\"text\"] = final_data['text'].apply(remove_non_arabic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GW3PG4oFwABB",
    "outputId": "2e4823d4-1453-4eab-e6d6-043321a277d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>اشتقت لي المشاكس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>ماشي يا مدام نظيفه يا فيتكه انتي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>تبقي تبقي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>ان الكرام وان ضاقت معيشتهم دامت فضيلتهم والاصل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>هه اموت في خفه الدم</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       neg                                   اشتقت لي المشاكس\n",
       "1       neg                   ماشي يا مدام نظيفه يا فيتكه انتي\n",
       "2       pos                                          تبقي تبقي\n",
       "3       pos  ان الكرام وان ضاقت معيشتهم دامت فضيلتهم والاصل...\n",
       "4       neg                                هه اموت في خفه الدم"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTaLH24GwABC",
    "outputId": "f13033f6-8c1b-4022-ef5f-eee4c0776078"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148328, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MfW1H03AwABC"
   },
   "outputs": [],
   "source": [
    "final_data[\"text\"] = final_data['text'].apply(lambda x:remove_repeating_char(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijjHF6y6wABC",
    "outputId": "f9f4eabb-7af0-4e34-e03e-ed60e38e121d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "We9cg4NNwABD",
    "outputId": "8ba8fa77-eb1c-4443-ff78-ff45280e0b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('arabic')\n",
    "print(len(stopwords_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "tYVYp7TCwABD",
    "outputId": "a50602b3-49b6-4c97-ad1e-1deed9cbcf52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'إذ إذا إذما إذن أف أقل أكثر ألا إلا التي الذي الذين اللاتي اللائي اللتان اللتيا اللتين اللذان اللذين اللواتي إلى إليك إليكم إليكما إليكن أم أما أما إما أن إن إنا أنا أنت أنتم أنتما أنتن إنما إنه أنى أنى آه آها أو أولاء أولئك أوه آي أي أيها إي أين أين أينما إيه بخ بس بعد بعض بك بكم بكم بكما بكن بل بلى بما بماذا بمن بنا به بها بهم بهما بهن بي بين بيد تلك تلكم تلكما ته تي تين تينك ثم ثمة حاشا حبذا حتى حيث حيثما حين خلا دون ذا ذات ذاك ذان ذانك ذلك ذلكم ذلكما ذلكن ذه ذو ذوا ذواتا ذواتي ذي ذين ذينك ريث سوف سوى شتان عدا عسى عل على عليك عليه عما عن عند غير فإذا فإن فلا فمن في فيم فيما فيه فيها قد كأن كأنما كأي كأين كذا كذلك كل كلا كلاهما كلتا كلما كليكما كليهما كم كم كما كي كيت كيف كيفما لا لاسيما لدى لست لستم لستما لستن لسن لسنا لعل لك لكم لكما لكن لكنما لكي لكيلا لم لما لن لنا له لها لهم لهما لهن لو لولا لوما لي لئن ليت ليس ليسا ليست ليستا ليسوا ما ماذا متى مذ مع مما ممن من منه منها منذ مه مهما نحن نحو نعم ها هاتان هاته هاتي هاتين هاك هاهنا هذا هذان هذه هذي هذين هكذا هل هلا هم هما هن هنا هناك هنالك هو هؤلاء هي هيا هيت هيهات والذي والذين وإذ وإذا وإن ولا ولكن ولو وما ومن وهو يا أبٌ أخٌ حمٌ فو أنتِ يناير فبراير مارس أبريل مايو يونيو يوليو أغسطس سبتمبر أكتوبر نوفمبر ديسمبر جانفي فيفري مارس أفريل ماي جوان جويلية أوت كانون شباط آذار نيسان أيار حزيران تموز آب أيلول تشرين دولار دينار ريال درهم ليرة جنيه قرش مليم فلس هللة سنتيم يورو ين يوان شيكل واحد اثنان ثلاثة أربعة خمسة ستة سبعة ثمانية تسعة عشرة أحد اثنا اثني إحدى ثلاث أربع خمس ست سبع ثماني تسع عشر ثمان سبت أحد اثنين ثلاثاء أربعاء خميس جمعة أول ثان ثاني ثالث رابع خامس سادس سابع ثامن تاسع عاشر حادي أ ب ت ث ج ح خ د ذ ر ز س ش ص ض ط ظ ع غ ف ق ك ل م ن ه و ي ء ى آ ؤ ئ أ ة ألف باء تاء ثاء جيم حاء خاء دال ذال راء زاي سين شين صاد ضاد طاء ظاء عين غين فاء قاف كاف لام ميم نون هاء واو ياء همزة ي نا ك كن ه إياه إياها إياهما إياهم إياهن إياك إياكما إياكم إياك إياكن إياي إيانا أولالك تانِ تانِك تِه تِي تَيْنِ ثمّ ثمّة ذانِ ذِه ذِي ذَيْنِ هَؤلاء هَاتانِ هَاتِه هَاتِي هَاتَيْنِ هَذا هَذانِ هَذِه هَذِي هَذَيْنِ الألى الألاء أل أنّى أيّ ّأيّان أنّى أيّ ّأيّان ذيت كأيّ كأيّن بضع فلان وا آمينَ آهِ آهٍ آهاً أُفٍّ أُفٍّ أفٍّ أمامك أمامكَ أوّهْ إلَيْكَ إلَيْكَ إليكَ إليكنّ إيهٍ بخٍ بسّ بَسْ بطآن بَلْهَ حاي حَذارِ حيَّ حيَّ دونك رويدك سرعان شتانَ شَتَّانَ صهْ صهٍ طاق طَق عَدَسْ كِخ مكانَك مكانَك مكانَك مكانكم مكانكما مكانكنّ نَخْ هاكَ هَجْ هلم هيّا هَيْهات وا واهاً وراءَك وُشْكَانَ وَيْ يفعلان تفعلان يفعلون تفعلون تفعلين اتخذ ألفى تخذ ترك تعلَّم جعل حجا حبيب خال حسب خال درى رأى زعم صبر ظنَّ عدَّ علم غادر ذهب وجد ورد وهب أسكن أطعم أعطى رزق زود سقى كسا أخبر أرى أعلم أنبأ حدَث خبَّر نبَّا أفعل به ما أفعله بئس ساء طالما قلما لات لكنَّ ءَ أجل إذاً أمّا إمّا إنَّ أنًّ أى إى أيا ب ثمَّ جلل جير رُبَّ س علًّ ف كأنّ كلَّا كى ل لات لعلَّ لكنَّ لكنَّ م نَّ هلّا وا أل إلّا ت ك لمّا ن ه و ا ي تجاه تلقاء جميع حسب سبحان شبه لعمر مثل معاذ أبو أخو حمو فو مئة مئتان ثلاثمئة أربعمئة خمسمئة ستمئة سبعمئة ثمنمئة تسعمئة مائة ثلاثمائة أربعمائة خمسمائة ستمائة سبعمائة ثمانمئة تسعمائة عشرون ثلاثون اربعون خمسون ستون سبعون ثمانون تسعون عشرين ثلاثين اربعين خمسين ستين سبعين ثمانين تسعين بضع نيف أجمع جميع عامة عين نفس لا سيما أصلا أهلا أيضا بؤسا بعدا بغتة تعسا حقا حمدا خلافا خاصة دواليك سحقا سرا سمعا صبرا صدقا صراحة طرا عجبا عيانا غالبا فرادى فضلا قاطبة كثيرا لبيك معاذ أبدا إزاء أصلا الآن أمد أمس آنفا آناء أنّى أول أيّان تارة ثمّ ثمّة حقا صباح مساء ضحوة عوض غدا غداة قطّ كلّما لدن لمّا مرّة قبل خلف أمام فوق تحت يمين شمال ارتدّ استحال أصبح أضحى آض أمسى انقلب بات تبدّل تحوّل حار رجع راح صار ظلّ عاد غدا كان ما انفك ما برح مادام مازال مافتئ ابتدأ أخذ اخلولق أقبل انبرى أنشأ أوشك جعل حرى شرع طفق علق قام كرب كاد هبّ'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listToStr = ' '.join([str(elem) for elem in stopwords_list])\n",
    "listToStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "OGWGw23mwABD"
   },
   "outputs": [],
   "source": [
    "final_data[\"text\"]=final_data[\"text\"].apply(lambda x: [item for item in x if item not in stopwords_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KE-knfzwABD",
    "outputId": "554b66fe-1187-4602-c2f2-985d92872fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1502257 words total, with a vocabulary size of 1\n",
      "Max sentence length is 1220\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in final_data[\"text\"] for word in tokens]\n",
    "sentence_lengths = [len(tokens) for tokens in final_data[\"text\"]]\n",
    "\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1oETLzkwyhLC"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-cb0rGXkwABE"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import text,sequence\n",
    "\n",
    "max_fatures = 10000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(final_data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(final_data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DjH-MLoym0G",
    "outputId": "aac131b1-750a-4a99-bf10-a72360fa8c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1220, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 1220, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 1,535,194\n",
      "Trainable params: 1,535,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 19:20:17.114484: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-01 19:20:17.114542: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-01 19:20:17.114569: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0a9436fdc9f): /proc/driver/nvidia/version does not exist\n",
      "2022-05-01 19:20:17.115914: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQUOljjiy3ig",
    "outputId": "8a8f9c90-047b-48a2-ebb7-1b1613b5306c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118662, 1220) (118662, 2)\n",
      "(29666, 1220) (29666, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(final_data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "5RGUOulgy_bY",
    "outputId": "ddd04e71-5bf4-4f47-a287-ec030cf069c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 19:20:30.635232: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7417/7417 [==============================] - 12151s 2s/step - loss: 0.6889 - accuracy: 0.5401\n",
      "Epoch 2/3\n",
      "7417/7417 [==============================] - 12160s 2s/step - loss: 0.6874 - accuracy: 0.5430\n",
      "Epoch 3/3\n",
      "7417/7417 [==============================] - 12099s 2s/step - loss: 0.6870 - accuracy: 0.5451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ac5b83490>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model.fit(X_train, Y_train, epochs = 3, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    ''' Function to calculate f1 score '''\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761/1761 [==============================] - 414s 235ms/step - loss: 0.6883 - accuracy: 0.5442\n",
      "\n",
      "Precision : 0.6883\n",
      "Recall    : 0.5442\n",
      "F1 Score  : 0.6078\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on the test set\n",
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "precision,recall= model.evaluate(X_test, Y_test, verbose=1, batch_size = batch_size)\n",
    "# Print metrics\n",
    "print('')\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM project -dataset2.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
